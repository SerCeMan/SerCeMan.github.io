<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
    <meta charset="utf-8"/>
    <title>SerCe&#39;s blog: Indirect Effects  of Allocate Direct</title>
    <link rel="canonical" href="http://serce.me/posts/18-11-2020-allocate-direct/">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.2.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/styles/default.min.css">
    <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Noto+Serif:400,400italic,700,700italic%7CRoboto%7CAlegreya:400italic,700italic,400,700">
    <link href="/css/screen.css" rel="stylesheet" type="text/css" />
    <link href="/css/main.css" rel="stylesheet" type="text/css" />
    <link href="/css/idea.css" rel="stylesheet" type="text/css" />
    <link href="/css/custom.css" rel="stylesheet" type="text/css" />
    
    <link href="/css/asciidoctor-default.css" rel="stylesheet" type="text/css" />

</head>
<body>


<nav class="navbar navbar-default">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar"
                    aria-expanded="false" aria-controls="navbar">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">SerCe&#39;s blog</a>
        </div>
        <div id="navbar" class="navbar-collapse collapse">
            <ul class="nav navbar-nav navbar-right">
                <li ><a href="/">Home</a></li>
                <li
                        ><a href="/archives/">Blog</a></li>
                
                <!--<li><a href="/feed.xml">RSS</a></li>-->
            </ul>
        </div><!--/.nav-collapse -->
    </div><!--/.container-fluid -->
</nav>



<div class="container">

    
<div class="row">
    <div class="col-lg-12">
        <div id="content">

            <div id="post">
                <div class="post-header">
    <div id="post-meta" class="row">
        <div class="col-lg-6">18 November 2020</div>
        
    </div>
    <h2>Indirect Effects  of Allocate Direct</h2>
</div>
<div>
    
    <div class="paragraph">
<p>Hi, folks!</p>
</div>
<div class="paragraph">
<p>Every single program allocates memory. Byte buffers are at the core of many essential libraries which power the services the modern internet is built upon. If you&#8217;re building such a library, or even just copying data between different files, chances are you&#8217;ll need to allocate a buffer.</p>
</div>
<div class="paragraph">
<p>In Java, <code>ByteBuffer</code> is the class that allows you to do so. Once you&#8217;ve decided to allocate a buffer, you&#8217;ll be presented with two methods <code>allocate()</code> and <code>allocateDirect()</code>. Which one to use? The answer is, as always, it depends. If there were no tradeoffs, there wouldn&#8217;t be two methods. In this article, I&#8217;ll explore some of these tradeoffs, demystify this behaviour, and I hope that the answer will be clear for you by the end of it.</p>
</div>
<div class="paragraph text-center">
<p><span class="image"><img src="/img/allocatedirect/itsgone.png" alt="itsgone"></span></p>
</div>
<div class="quoteblock text-center">
<blockquote>
<div class="paragraph">
<p>Yeah well, sometimes the things we do donâ€™t matter right now. Sometimes they matter later. We have to care more about later sometimes, you know.</p>
</div>
</blockquote>
<div class="attribution">
&#8212; Stan Marsh
</div>
</div>
<div class="sect2">
<h3 id="_two_buffers">Two buffers</h3>
<div class="paragraph">
<p>At first glance, the two methods <code>allocate()</code> and <code>allocateDirect()</code> are very simple. The <code>allocate()</code> allocates a buffer in the managed heap of the Java process, a part of this exact space which size is specified with the <code>Xmx</code> option. The <code>allocateDirect()</code> method allocates a buffer residing outside of the managed heap.</p>
</div>
<div class="paragraph">
<p><span class="image"><img src="/img/allocatedirect/server3.png" alt="server3"></span></p>
</div>
<div class="paragraph">
<p>This difference, however, creates a number of significant runtime implications, which I&#8217;m going to dive into here. But first, let me start by telling a debugging story where direct byte buffers were the murderer.</p>
</div>
</div>
<div class="sect2">
<h3 id="_the_story">The story</h3>
<div class="paragraph">
<p>Every story needs a protagonist. In this case, the protagonist was a Java application built on top of RSocket, a modern application protocol. Here&#8217;s the oversimplified version of the app which you can find on <a href="https://github.com/SerCeMan/allocatedirect/blob/master/src/main/java/me/serce/allocatedirect/Main.java">Github</a>. Let&#8217;s call this app an echo app. The echo code isn&#8217;t trying to do anything complicated, it is a simple echo service built with an awesome <a href="https://github.com/rsocket/rsocket-java">rsocket-java</a> library. All it does is spins up a client and a server, where the client sends messages, and the server echoes them back.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">var server = RSocketServer.create(echo) //...
var client = RSocketConnector.create() //...
while (true) {
  assert Objects.equals(client.send(), client.receive())
}</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The supporting code for this article is available <a href="https://github.com/SerCeMan/allocatedirect">on Github</a>. You can, and I highly encourage you to, choose to go through each step yourself by cloning the code and running each example with a simple bash script. All measurements were taken on an EC2 AWS <a href="https://aws.amazon.com/ec2/instance-types/m5/">m5.large</a> instance. Unless specified otherwise, <em>Java 13</em> is used. The point of this article is not to show the numbers but rather demonstrate the techniques that you can use to debug your own application.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The code is useless if it&#8217;s just sitting in the repo and doing nothing, so let&#8217;s clone the repo and start the app.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">git clone https://github.com/SerCeMan/allocatedirect.git
cd allocatedirect &amp;&amp; ./start.sh</code></pre>
</div>
</div>
<div class="paragraph">
<p>The app starts, and you should see that the logs are flowing. As expected, now it&#8217;s processing a large number of messages. However, if the echo app was exposed to users, they would start noticing significant pauses every now and then. All Java developers know that the first thing to look at in the case of spurious pauses is GC.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
You can find GC logs of the app are stored in <code>/tmp/${gcname}</code>. The example logs for each run are also available in the <a href="https://github.com/SerCeMan/allocatedirect/tree/master/logs">repo</a>. In this article, gceasy.io was used for visualisation. It&#8217;s a great free online tool which supports the log format of multiple garbage collectors. Even though you can always visualise GC logs using a tool like gceasy, as we&#8217;ll see later, the raw logs often contain a lot more information than most of the tools can display.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Indeed, GC logs show that GC is to blame here. The application is running under G1, which is the default collector since JDK 9. There are multiple young GC pauses on the graph. Young GC is a stop-the-world pause in GC in G1. The application stops completely to perform a cleanup. For the echo server, the graph shows multiple young GC pauses that last for 100-130ms and occur every 10 seconds.</p>
</div>
<div class="paragraph text-center">
<div class="title">G1 GC</div>
<p><span class="image"><img src="/img/allocatedirect/g1before.png" alt="g1before"></span></p>
</div>
<div class="paragraph">
<p>Luckily for us, in the last few years, there has been an amazing development in the GC space. There are not just one but two new fully concurrent garbage collectors, <a href="https://wiki.openjdk.java.net/display/zgc/Main">ZGC</a> and <a href="https://wiki.openjdk.java.net/display/shenandoah/Main">Shenandoah</a>.</p>
</div>
<div class="paragraph">
<p>While I&#8217;ve had <a href="https://twitter.com/SerCeMan/status/1246676501925224449">great success</a> with ZGC before, Shenandoah has a great advantage of being much friendlier to application memory consumption. Many applications, especially simple JSON in, JSON out stateless services are not memory-constrained. Some application, on the other hand, especially the ones that process a large number of connections might be very sensitive to memory usage.</p>
</div>
<div class="paragraph">
<p>Even though the echo app only has a single client and a server in its current state, it could as well handle tens of thousands of connections. It&#8217;s time to enable Shenandoah,  and run the echo app again.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash">./start.sh shen # starts with -XX:+UseShenandoahGC</code></pre>
</div>
</div>
<div class="paragraph">
<p>After enabling Shenandoah, the GC logs start showing an interesting picture. There is definitely a huge improvement in the pause frequency. The pauses now only occur every minute or so. However, the pauses are still around 90ms long, which is far away from the desired sub-millisecond pauses.</p>
</div>
<div class="paragraph text-center">
<div class="title">Shenandoah GC</div>
<p><span class="image"><img src="/img/allocatedirect/shenandoah.png" alt="shenandoah"></span></p>
</div>
<div class="paragraph">
<p>Now that the symptoms are clear, and the problem is reproducible, it&#8217;s time to look at the cause. GC graphs don&#8217;t show much more information. Looking at the raw logs directly, on the other hand, reveals the cause which is clearly stated right on the pause line.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-log" data-lang="log">...
[info][gc] GC(15) Pause Final Mark (process weakrefs) 86.167ms
...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Turns out, weak references are to blame. Put simply, weak references are a way to keep an object in memory until there is a demand for this memory. Large in-memory caches is a common use-case for weak references. If there is enough free heap, a weak reference cache entry can stay there. As soon as GC figures out that there is not enough memory, it&#8217;ll deallocate weak references. In most of the cases, this is a much better outcome than the application failing with an out of memory exception because of a cache.</p>
</div>
<div class="paragraph">
<p>A frantic search across the repository doesnâ€™t show any usages of weak, soft or phantom references. Not even the search through the third party libraries can show anything. After staring at the metrics for a while, one of the graphs gives a clue! The long GC pauses correlate with a sudden drop in the number of direct byte buffers.</p>
</div>
<div class="paragraph text-center">
<div class="title">GC vs DirectByteBuffer count</div>
<p><span class="image"><img src="/img/allocatedirect/jmc-gc.png" alt="jmc gc"></span></p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
You can get a similar graph by running the echo app and connecting to the JMX port. For this screenshot, I used Java Mission Control (JMC). The <a href="https://github.com/SerCeMan/allocatedirect/blob/master/start.sh#L53">start.sh</a> script contains the options that you can enable to connect to an app with JMX remotely.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>At first, the correlation might not make any sense. Byte buffers are not weak references, are they? They are not weak references themselves. However, you might notice, that creating a new direct byte buffer gives you back a plain <code>ByteBuffer</code> interface which doesn&#8217;t have a <code>close</code> method or any other way of deallocating the buffer.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">ByteBuffer buf = ByteBuffer.allocateDirect(42);</code></pre>
</div>
</div>
<div class="paragraph">
<p>The underlying buffer needs to go away once the last reference to this buffer goes away. The modern API for this in Java is <a href="https://docs.oracle.com/en/java/javase/13/docs/api/java.base/java/lang/ref/Cleaner.html"><code>java.lang.ref.Cleaner</code></a>. As we can see, it&#8217;s exactly what <code>DirectByteBuffer</code> class uses to determine when the underlying buffer should be deallocated.</p>
</div>
<div class="listingblock">
<div class="title"><a href="https://github.com/openjdk/jdk13/blob/dcd4014cd8a6f49a564cbb95387ad01a80a20bed/src/java.base/share/classes/java/nio/Direct-X-Buffer.java.template#L113-L141">DirectByteBuffer</a> constructor</div>
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">DirectByteBuffer(int cap) {
    // ...
    base = UNSAFE.allocateMemory(size); // malloc call
    UNSAFE.setMemory(base, size, (byte) 0);
    // ...
    cleaner = Cleaner.create(this, new Deallocator(base, size, cap));
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Yet, there are no usages of direct buffers in the code of the echo app either, so how could we find them? One way would be to search through the third party libraries using IntelliJ. The approach would work very well for the echo example but would completely fail for any real applications of a decent size. There are just way too many places where byte buffers are used. Looking at the graphs, one can notice that the number of created buffers per minute is huge, literally millions of them.</p>
</div>
<div class="paragraph">
<p>Instead of searching through the code to find all byte buffer references, it is easier to find the place at runtime. One way to find out where the majority of the buffers is created is to fire up the async profiler and profile the <a href="https://man7.org/linux/man-pages/man3/malloc.3.html"><code>malloc</code></a> calls which are used by direct buffers to allocate memory.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># async profiler can be downloaded from https://github.com/jvm-profiling-tools/async-profiler
./profiler.sh -d 30 -f /tmp/flamegraph.svg $(pgrep -f java) -e malloc</code></pre>
</div>
</div>
<div class="paragraph">
<p>While running, the profiler managed to sample more than 500000 malloc calls which non-ambiguously show where all of the buffers were created from.</p>
</div>
<div class="paragraph text-center">
<div class="title">malloc calls</div>
<p><span class="image"><object type="image/svg+xml" data="/img/allocatedirect/mallocflame.svg"><span class="alt">mallocflame</span></object></span></p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
The flame graph above visualises the code paths where most of the captured malloc calls occur. The wider the column is, the larger the number of times the code path appeared in the sample. This graph, as well as other flame graphs in this article, is clickable. You can read more on how to read flame graphs <a href="http://www.brendangregg.com/flamegraphs.html">here</a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>As it turned out, there was a place in the code which was using direct buffers. With this rich knowledge of where exactly the direct buffer allocations occur, creating a fix is easy. All that&#8217;s needed is to make a one line change and to replace <code>allocateDirect</code> with <code>allocate</code> and send a <a href="https://github.com/rsocket/rsocket-java/pull/945">PR upstream</a>.</p>
</div>
<div class="paragraph">
<p>Running the same app on shenandoah after applying the single line change produces a completely different graph which pleases the eyes with sub-millisecond GC pauses.</p>
</div>
<div class="paragraph text-center">
<div class="title">Shenandoah GC</div>
<p><span class="image"><img src="/img/allocatedirect/shenandoah-heap.png" alt="shenandoah heap"></span></p>
</div>
</div>
<div class="sect2">
<h3 id="_the_costs">The costs</h3>
<div class="paragraph">
<p>The story revealed a dark side of direct byte buffers. If there is a dark side, there must be a bright side as well! There is. But before we look at the bright side, we need to explore a few more sides which also appeared to be grey.</p>
</div>
<div class="sect3">
<h4 id="_allocations">Allocations</h4>
<div class="paragraph">
<p>Previously, weâ€™ve observed implicit deallocations costs, so now itâ€™s time to take a look at allocations. Could direct buffers be much cheaper to create? After all, going off-heap has been a performance trend for a while. A small benchmark can help to estimate the costs.</p>
</div>
<div class="listingblock">
<div class="title"><a href="https://github.com/SerCeMan/allocatedirect/blob/master/bench/src/main/java/me/serce/AllocateBuffer1.java">AllocationBenchmark.java</a></div>
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">@Param({"128", "1024", "16384"})
int size;

@Benchmark
public ByteBuffer heap() {
  return ByteBuffer.allocate(size);
}

@Benchmark
public ByteBuffer direct() {
  return ByteBuffer.allocateDirect(size);
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>After cloning the repo, you can run the benchmark yourself with the command below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-bash" data-lang="bash"># Don't just read! Clone the repo and try yourself! ðŸ¤“
./bench.sh alloc1</code></pre>
</div>
</div>
<div class="paragraph">
<p>The absolute numbers are not that interesting. Even the slowest operation only takes a few microseconds. But the difference between the heap buffers and direct buffers is fascinating.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>Benchmark               (size)  Mode  Cnt     Score     Error  Units
AllocateBuffer1.direct     128  avgt    5  1022.137 Â± 148.510  ns/op
AllocateBuffer1.heap       128  avgt    5    23.969 Â±   0.051  ns/op

AllocateBuffer1.direct    1024  avgt    5  1228.785 Â± 127.090  ns/op
AllocateBuffer1.heap      1024  avgt    5   179.350 Â±   2.989  ns/op

AllocateBuffer1.direct   16384  avgt    5  3039.485 Â± 111.714  ns/op
AllocateBuffer1.heap     16384  avgt    5  2620.722 Â±   5.395  ns/op</code></pre>
</div>
</div>
<div class="paragraph">
<p>Even though direct buffers lose in all of the runs, the difference is much more noticeable on small buffers while on large buffers, the overhead is almost negligible. Due to the 50x difference on a small buffer, itâ€™s a much more compelling example to look into. Letâ€™s start a benchmark again, make it run for much longer, and use async profiler to see what where the time is spent.</p>
</div>
<div class="paragraph text-center">
<div class="title">ByteBuffer.allocateDirect()</div>
<p><span class="image"><object type="image/svg+xml" data="/img/allocatedirect/alloc_direct_perf.svg"><span class="alt">alloc direct perf</span></object></span></p>
</div>
<div class="paragraph">
<p>The flame graph already hints towards some of the overhead. Not only the direct buffers need to allocate memory, but it also needs to reserve it to check the maximum native memory limit. On top of this, the buffer needs to be zeroed as <code>malloc</code> can&#8217;t guarantee that it doesn&#8217;t return you some garbage while the buffer needs to be ready to use. And finally, it needs to register itself for deallocation as a soft reference. All of this seems like a lot of work, but the actual allocation still takes a half of the time! So, even if the heap buffer doesn&#8217;t need to do any work other than calling <code>malloc</code>, it should only be as twice as slow, not 50 times! Profiling heap buffer allocations can hopefully reveal where such a vast difference is coming from.</p>
</div>
<div class="paragraph text-center">
<div class="title">ByteBuffer.allocate()</div>
<p><span class="image"><object type="image/svg+xml" data="/img/allocatedirect/alloc_heap_perf.svg"><span class="alt">alloc heap perf</span></object></span></p>
</div>
<div class="paragraph">
<p>The heap buffer flame graph is surprisingly blank. There isn&#8217;t much happening on the graph. Yet, there are still some allocations in the yellow flame tower on the right. However, the whole allocation path only takes 2% of the time, and the rest is nothing? Exploring the yellow tower gives a further clue. Most of its time is taken by a function that&#8217;s called <code>MemAllocator::allocate_inside_tlab_slow</code>. The meaning of the <code>allocate_slow</code> part is self-explanatory, but it&#8217;s <code>inside_tlab</code> that is the answer.</p>
</div>
<div class="paragraph">
<p>TLAB stands for Thread Local Allocation Buffer. TLAB is a space in the Eden, the space where all new objects are born, dedicated for each thread to allocate objects. When different threads allocate memory, they donâ€™t have to contend on the global memory. Every thread allocates objects locally, and because the buffer is not shared with other threads, there is no need to use call <code>malloc</code>. All thatâ€™s needed is to move the pointer by a few bytes. The fact that most of the allocations happen in TLAB could explain why heap buffers are so much faster when their size is small. When the size is large, the allocations wonâ€™t occur in TLAB due to the limits on its size, which will result in buffer allocation times being almost on par.</p>
</div>
<div class="paragraph">
<p>Now that we&#8217;ve assumed that we know why it&#8217;s so much faster, can we jump to the next section? Not so fast!</p>
</div>
<div class="paragraph">
<p>So far, TLAB is just a theory, and we need to conduct an experiment to validate it. One of the easiest ways is to simply disable TLAB with the <code>-XX:-UseTLAB</code> options.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">// run with ./bench.sh alloc4
@Fork(jvmArgsAppend = { "-XX:-UseTLAB" })
@Benchmark
public ByteBuffer heap() {
  return ByteBuffer.allocate(size);
}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>Benchmark             (size)  Mode  Cnt    Score   Error  Units
AllocateBuffer2.heap     128  avgt    5  151.999 Â± 8.477  ns/op</code></pre>
</div>
</div>
<div class="paragraph">
<p>Were we right? Yes and no. The performance results with disabled TLAB are not as impressive anymore. Though, the pure allocation time is still about three times faster even considering that the benchmark needs to not only allocate memory for the buffer itself but also for the <code>ByteBuffer</code> class. The still significant difference shows the cost of going back to the operating system with a syscall every time to ask for more memory with occasional page faults.</p>
</div>
<div class="paragraph text-center">
<div class="title">ByteBuffer.allocate(), -XX:-UseTLAB</div>
<p><span class="image"><object type="image/svg+xml" data="/img/allocatedirect/alloc_heap_no_tlab.svg"><span class="alt">alloc heap no tlab</span></object></span></p>
</div>
<div class="paragraph">
<p>As a rule of thumb, if your buffers are mostly short-lived and small, using heap byte buffers will likely be a more performant choice for you. Conveniently, it&#8217;s exactly what the javadoc of the ByteBuffer class is warning us about.</p>
</div>
<div class="quoteblock">
<blockquote>
It is therefore recommended that direct buffers be allocated primarily for large, long-lived buffers that are subject to the underlying system&#8217;s native I/O operations.
</blockquote>
<div class="attribution">
&#8212; ByteBuffer.java
</div>
</div>
<div class="sect4">
<h5 id="_memory_costs">Memory costs</h5>
<div class="paragraph">
<p>So far, we&#8217;ve only been measuring allocations. Still, looking at the flame graphs, we can also see the de-allocation path which is frequently invoked by JMH that runs the benchmarks by explicitly invoking <a href="https://github.com/openjdk/jmh/blob/4264de9486c32b48da8161e3ac076a0187b4176f/jmh-core/src/main/java/org/openjdk/jmh/runner/BaseRunner.java#L273"><code>System.gc()</code></a> and finalization before each iteration. That way, the previously allocated buffers will be deallocated.</p>
</div>
<div class="paragraph">
<p>However, in the real applications, as we saw in the debugging story, we&#8217;re at a mercy of the GC to deallocate those buffers. In this case, the amount of memory consumed by the app might be hard to predict as it depends on the GC and how the GC behaves on this workload. For how long would the following code run?</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">public class HeapMemoryChaser {
  public static void main(String[] args) {
    while (true) {
      ByteBuffer.allocate(1024);
    }
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>The code above contains an infinite loop, so you can say forever, and you will be completely right. There are no conditions, so there is nothing that can prevent the loop from running. Will this snippet run forever too?</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">public class DirectMemoryChaser {
  public static void main(String[] args) {
    while (true) {
      ByteBuffer.allocateDirect(1024);
    }
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Will the above code run forever as well? It depends on how lucky we are. There are no guarantees on when a GC would clean up the allocated direct buffers. Various JVM options can vary the result from run forever with no issues to a crash after a few seconds. Running the above code with <code>-Xmx6G</code> on a VM with 8GB RAM runs for about 20 seconds until it gets killed by the operating system.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ time java -Xmx6G DirectMemoryChaser
Killed

real	0m24.211s</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>dmesg</code> shows an insightful message explaining that the process was killed due to lack of memory.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>[...] Out of memory: Killed process 4560 (java) total-vm:10119088kB, anon-rss:7624780kB, file-rss:1336kB, shmem-rss:0kB, UID:1000 pgtables:15216kB oom_score_adj:0
[...] oom_reaper: reaped process 4560 (java), now anon-rss:0kB, file-rss:0kB, shmem-rss:0kB</code></pre>
</div>
</div>
<div class="paragraph">
<p>Allocating direct buffers without care can cause the app to go far beyond the expected memory usage as there are no guarantees on when the soft references are going to be cleaned. Crashing right after the start is counterintuitively a good result. At least, you can observe the failure, reproduce it, understand it and fix it. A crash after a few hours of running is much worse, and without a clear feedback loop, it&#8217;s much harder to resolve the issue.</p>
</div>
<div class="paragraph">
<p>When debugging such issues, or as a preventative measure, consider using <code>-XX:+AlwaysPreTouch</code> to at least exclude the heap growth out of the equation. One way to prevent this is to run the infinite growth of direct buffers is to use <code>-XX:MaxDirectMemorySize=${MAX_DIRECT_MEM}</code> to ensure that the usage of direct memory doesn&#8217;t grow uncontrollably.</p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_the_benefits">The benefits</h3>
<div class="paragraph">
<p>So far, the direct byte buffers have only caused troubles. In the story, switching to heap-based byte buffers was a clear win, though there are a lot of hidden dangers in using them. Would it be reasonable to use heap byte buffers only and never use direct buffers? The choice exists for a reason, and there reasons to use direct buffers.</p>
</div>
<div class="sect3">
<h4 id="_off_heap_graal">Off Heap Graal</h4>
<div class="paragraph">
<p>We have observed problems with allocations and deallocations, so what if a buffer is only allocated once and never deallocated? One buffer is not enough most of the time, so you can create a pool of buffers, borrow them for some time and then return back. It is what Netty does with their <a href="https://netty.io/wiki/using-as-a-generic-library.html"><code>ByteBuf</code></a> classes which are built to fix some of the downsides of the <code>ByteBuffer</code> class. Nevertheless, it&#8217;s still not clear why one should prefer direct buffers over heap buffers.</p>
</div>
<div class="paragraph">
<p>Avoiding GC altogether could be one of the reason. You could be managing terabytes of memory without any GC overhead. While you could manage large amounts of memory with direct byte buffers, there is a limit of 2^31 on the indices that you can use with a single buffer. A solution is coming in the form of a <a href="https://openjdk.java.net/jeps/383">Foreign-Memory Access API</a> which is available for the second preview in JDK 15. But avoiding GC is not the main reason.</p>
</div>
</div>
<div class="sect3">
<h4 id="_io">IO</h4>
<div class="paragraph">
<p>The IO is where direct byte buffers shine! Let&#8217;s say we need to copy some memory between two files. Heap byte buffers are obviously backed by memory in a heap, so the contents of the files would have to be copied to be sent back seconds later. This can be avoided completely with direct byte buffers. Direct byte buffers excel when you don&#8217;t need a buffer per se but rather a pointer to a piece of memory somewhere outside of the heap. Again, at this point, this is only a hypothesis of a random person on the internet. Let&#8217;s prove or disprove it with the following benchmark.</p>
</div>
<div class="listingblock">
<div class="title"><a href="https://github.com/SerCeMan/allocatedirect/blob/master/bench/src/main/java/me/serce/CopyFileBenchmark.java">CopyFileBenchmark.java</a></div>
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">@Benchmark // ./bench.sh reverse
public void reverseBytesInFiles() throws Exception {
  ByteBuffer buf = this.buffer;
  buf.clear();
  try (FileChannel channel1 = FileChannel.open(Paths.get(DIR + "file1"), READ);
       FileChannel channel2 = FileChannel.open(Paths.get(DIR + "file2"), WRITE)) {
    while (buf.hasRemaining()) {
      channel1.read(buf);
    }
    buf.put(0, buf.get(SIZE - 1));
    buf.flip();
    while (buf.hasRemaining()) {
      channel2.write(buf);
    }
  }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>The code above reads  64 MB of random data from the first files, reverses the byte order of each long in the array and then puts it back. Reversing the first and the last bytes here is a tiny operation which the only goal is to modify the contents of the file in some way as copying could simply be done by calling <code>channel.transferTo</code>.</p>
</div>
<div class="paragraph">
<p>The results show that the direct buffer is the clear winner, almost twice as fast!</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>Benchmark                              (bufferType)  Mode  Cnt   Score   Error  Units
CopyFileBenchmark.reverseBytesInFiles        direct  avgt    5  36.383 Â± 0.683  ms/op
CopyFileBenchmark.reverseBytesInFiles          heap  avgt    5  59.816 Â± 0.834  ms/op</code></pre>
</div>
</div>
<div class="paragraph">
<p>The next step is to understand where the time was spent to validate our hypothesis. Taking a flamegraph for the direct buffer shows what we expected â€” all of the time spent in kernel reading and writing files.</p>
</div>
<div class="paragraph text-center">
<div class="title">Directy Buffer</div>
<p><span class="image"><object type="image/svg+xml" data="/img/allocatedirect/reverse_offheap.svg"><span class="alt">reverse offheap</span></object></span></p>
</div>
<div class="paragraph">
<p>For the heap buffer, for both operations, reading and writing, the memory has to be copied first between the buffers which we can clearly see from the flamegraph. A solid chunk of it is taken by the <code>copyMemory</code> function.</p>
</div>
<div class="paragraph text-center">
<div class="title">Heap Buffer</div>
<p><span class="image"><object type="image/svg+xml" data="/img/allocatedirect/reverse_heap.svg"><span class="alt">reverse heap</span></object></span></p>
</div>
<div class="paragraph">
<p>The IO here does not only refer to writing to disk, but it can also be writing to a socket which is what a considerable portion of the java applications is performing all day non-stop. As you can see, carefully choosing your buffers can significantly affect performance.</p>
</div>
</div>
<div class="sect3">
<h4 id="_endianness">Endianness</h4>
<div class="paragraph">
<p>Can direct byte buffers be even faster? While reading the javadoc for create methods, note an important remark:</p>
</div>
<div class="quoteblock">
<blockquote>
The new buffer&#8217;s position will be zero, its limit will be its capacity, its mark will be undefined, each of its elements will be initialized to zero, and its byte order will be ByteOrder#BIG_ENDIAN.
</blockquote>
<div class="attribution">
&#8212; ByteBuffer.java
</div>
</div>
<div class="paragraph">
<p>The byte order of byte buffers created in java is always big endian by default. While having an always predictable default is great, it also means that sometimes, it might not match the endianness of the underlying platform. In the case of an <code>m5.large</code> AWS instance, this is indeed the case.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-shell" data-lang="shell">jshell&gt; java.nio.ByteOrder.nativeOrder()
$1 ==&gt; LITTLE_ENDIAN</code></pre>
</div>
</div>
<div class="paragraph">
<p>This fact immediately raises the question if, or rather when changing endianness can yield any significant performance wins. The only way to find out is to measure it.</p>
</div>
<div class="listingblock">
<div class="title"><a href="https://github.com/SerCeMan/allocatedirect/blob/master/bench/src/main/java/me/serce/OrderBenchmark.java">OrderBenchmark.java</a></div>
<div class="content">
<pre class="highlight"><code class="language-java" data-lang="java">static final int SIZE = 1024 * 1024 * 1024;

@Param({"direct-native-order", "direct"})
String bufferType;

@Setup
public void setUp() throws Exception {
  switch (bufferType) {
    case "direct":
      buffer = ByteBuffer.allocateDirect(SIZE); break;
    case "direct-native-order":
      buffer = ByteBuffer.allocateDirect(SIZE).order(ByteOrder.nativeOrder()); break;
  }
  channel = FileChannel.open(Paths.get("/dev/urandom"), READ);
  while (buffer.hasRemaining()) { channel.read(buffer); }
  buffer.flip();
  this.buffer = buffer.asLongBuffer();
}

@Benchmark // run with ./bench.sh order
public long sumBytes() {
  long sum = 0;
  for (int i = 0; i &lt; SIZE / 8; i++) {
    sum += buffer.get(i);
  }
  return sum;
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>The above benchmark measures a specific use-case. We load a gigabyte worth of random longs into memory. Then, we simply read them one by one. Itâ€™s interesting that depending on the endianness, the result will be different as it affects the order of the bytes. We donâ€™t care about the byte order for this use-case, however, as a random value with reversed byte order is still a random value.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>Benchmark                       (bufferType)  Mode  Cnt    Score   Error  Units
OrderBenchmark.sumBytes  direct-native-order  avgt    5  136.025 Â± 2.262  ms/op
OrderBenchmark.sumBytes               direct  avgt    5  195.980 Â± 8.360  ms/op</code></pre>
</div>
</div>
<div class="paragraph">
<p>The first impression is that iterating through a gigabyte worth of random memory is pretty darn fast. The second is that the native order byte buffer is performing 1.5 times faster! As before, running async profiler helps to reveal the reason why the native order is more performant.</p>
</div>
<div class="paragraph text-center">
<div class="title">Non-native (Big Endian)</div>
<p><span class="image"><object type="image/svg+xml" data="/img/allocatedirect/sum_big_endian.svg"><span class="alt">sum big endian</span></object></span></p>
</div>
<div class="paragraph text-center">
<div class="title">Native (Little Endian)</div>
<p><span class="image"><object type="image/svg+xml" data="/img/allocatedirect/sum_native_endian.svg"><span class="alt">sum native endian</span></object></span></p>
</div>
<div class="paragraph">
<p>Comparing the graphs above, the first difference that stands out is that byte buffer classes are actually different depending on the byte order. The native buffer is <code>DirectLongBufferU</code> while the non-native one is <code>DirectLongBufferS</code>. The main difference between them is the presence of the <code>Bits.swap</code> method.</p>
</div>
<div class="paragraph">
<p>Looking further into the method, we can see that it delegates directly to <code>Long.reverseBytes</code>. While its implementation in Java is quite complex, one can notice the <code>@HotSpotIntrinsicCandidate</code> annotation. The annotation is a signal that at runtime, JIT could replace the method with pre-prepared assembly code. Adding a set of JVM options, <code>-XX:CompileCommand=print,*OrderBenchmark.sumBytes*</code>, to the benchmark allows us to peek at the resulting assembly code to understand how exactly the <code>reverseBytes</code> affects the resulting code.</p>
</div>
<table class="tableblock frame-all grid-cols stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Non-native (Big Endian)</th>
<th class="tableblock halign-left valign-top">Native (Little Endian)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><div class="content"><div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-x86asm" data-lang="x86asm">....
loop:
 mov    r10d,DWORD PTR [rdx+0x14]
 mov    ecx,DWORD PTR [r10+0x8]
 mov    r8,r10                  ; &lt;- buffer
 cmp    ecx,0x16577b
 jne    0x00007f9d5c277070
 mov    ebx,DWORD PTR [r8+0x1c] ; &lt;- limit
 cmp    r11d,ebx
 jge    0x00007f9d5c277078  ; checkIndex(i)
 mov    r10,QWORD PTR [r8+0x10]
 movsxd r8,r11d
 shl    r8,0x3
 add    r8,r10
 mov    r10,r8
 mov    r10,QWORD PTR [r10] ; r10 = get(i)
 bswap  r10                 ; reverseBytes(r10)
 add    rax,r10             ; sum += r10
 inc    r11d                ; i+=1
 cmp    r11d,0x8000000      ; i &lt; SIZE/8
 jl     loop
...</code></pre>
</div>
</div></div></td>
<td class="tableblock halign-left valign-top"><div class="content"><div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-x86asm" data-lang="x86asm">...
loop:
 mov    r11d,DWORD PTR [r8+0x14] ; &lt;- buffer
 mov    r9d,DWORD PTR [r11+0x1c] ; &lt;- limit
 cmp    ecx,r9d
 jge    0x00007f268c274f57 ; checkIndex(i)
 mov    r10,QWORD PTR [r11+0x10]
 movsxd r11,ecx
 shl    r11,0x3
 add    r11,r10
 mov    r10,r11
 add    rbx,QWORD PTR [r10] ; sum += get(i)
 inc    ecx                 ; i+=1
 cmp    ecx,0x8000000       ; i &lt; SIZE/8
 jl     loop
...</code></pre>
</div>
</div></div></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>Comparing the compilations listings of these two implementations, we can notice that the biggest difference between them is the <code>bswap</code> instruction which is the essence of the <code>Bytes.swap</code> method. As expected, it reverses the byte order every time a long is read from the buffer.</p>
</div>
<div class="paragraph">
<p>Reading a gigabyte of memory into longs is an interesting workload, but itâ€™s not necessarily the one that youâ€™re likely to encounter in production. Endianness can be a useful thing to remember about, but unless working with native libraries or working with massive files, itâ€™s unlikely to be a concern.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_conclusion">Conclusion</h3>
<div class="paragraph">
<p>Every non-trivial Java application directly or indirectly uses byte buffers. On the surface, ByteBuffer is a simple class. Itâ€™s just a pointer to a chunk of memory. Nevertheless, even by looking at such a simple class, you can discover a deep rabbit hole. Even though weâ€™ve only looked at the tip of the iceberg, I hope that you have a clear idea now of when you could use a heap buffer, and when you would choose a direct buffer.</p>
</div>
<div class="paragraph">
<p>Modern JVM runtimes are complicated environments. While they provide sane defaults, they also present multiple options. The choice is always there, it&#8217;s up to you to make that choice, but it&#8217;s crucial to be aware of the consequences. Fortunatelly, JVM runtimes also come with a whole lot of various observability tools, JMX metrics, GC logs, profilers, and if you really want it&#8217;s not even that hard to look at the generated assembly code. Using techniques shown in this article, you can make a choice not for the workload of a guy from the internet, but for <em>your</em> workload, which can result in amazing results in production later. We have to care more about later sometimes, you know.</p>
</div>
</div>
<div class="sect2">
<h3 id="_thank_you_to">Thank you to</h3>
<div class="ulist">
<ul>
<li>
<p>Uri Baghin, and <a href="https://twitter.com/ptuls">Paul Tune</a> for reviewing the article.</p>
</li>
<li>
<p>You for reading the article.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Are you as passionate about Java as I and my colleagues at Canva are? <a href="https://jobs.lever.co/canva/ca10485f-80af-4fa4-9367-9558304cd614?cp=reactivejobs">Join us</a>!</p>
</div>
</div>
<div class="sect2">
<h3 id="_share_this_article">Share this article</h3>
<hr>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">&quot;You don&#39;t need no Service Mesh&quot;. Just published a new blog post with an anti-hype opinion on the over-hyped topic. <a href="https://t.co/SVXS3nWKzj">https://t.co/SVXS3nWKzj</a></p>&mdash; Sergey Tselovalnikov (@SerCeMan) <a href="https://twitter.com/SerCeMan/status/1286242507664191488?ref_src=twsrc%5Etfw">July 23, 2020</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
<div class="sect2">
<h3 id="_references">References</h3>
<div class="ulist">
<ul>
<li>
<p><a href="https://github.com/jvm-profiling-tools/async-profiler/">Async Profiler</a></p>
</li>
<li>
<p><a href="https://www.youtube.com/watch?v=iwSCtxMbBLI">Beyond ByteBuffers by Brian Goetz</a></p>
</li>
<li>
<p><a href="https://gceasy.io/">GC Easy GC Analyser</a></p>
</li>
<li>
<p><a href="https://shipilev.net/jvm/anatomy-quarks/4-tlab-allocation/">JVM Anatomy Quark #4: TLAB allocation</a></p>
</li>
<li>
<p><a href="https://www.youtube.com/watch?v=DKJ0w30M0vg">Netty - One Framework to rule them all by Norman Maurer</a></p>
</li>
<li>
<p><a href="https://netty.io/wiki/using-as-a-generic-library.html">Netty&#8217;s ByteBuf API</a></p>
</li>
</ul>
</div>
</div>
</div>

<div id="post-tags">
    <b>Tags: </b>
    
    <a href="/tags/bytebuffers/">bytebuffers</a>
    
    <a href="/tags/java/">java</a>
    
</div>


                <div id="prev-next">
                    
                    
                    <a class="right" href="/posts/23-07-2020-you-dont-need-no-service-mesh/">You don&#39;t need no Service Mesh &raquo;</a>
                    
                </div>

                
                <div id="disqus_thread"></div>
                <script type="text/javascript">
                    (function () {
                        var dsq = document.createElement('script');
                        dsq.type = 'text/javascript';
                        dsq.async = true;
                        dsq.src = '//serceman.disqus.com/embed.js';
                        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
                    })();
                </script>
                


            </div>
        </div>
    </div>
</div>

    <footer>Copyright &copy;  Sergey Tselovalnikov
    </footer>
</div>
<script src="/js/highlight.pack.js" type="text/javascript"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-77409445-1', 'auto');
  ga('send', 'pageview');
</script>
</body>
</html>
