<?xml version='1.0' encoding='UTF-8'?>
<rss version='2.0' xmlns:atom='http://www.w3.org/2005/Atom'>
<channel>
<atom:link href='http://serce.me/' rel='self' type='application/rss+xml'/>
<title>
SerCe's blog
</title>
<link>
http://serce.me/
</link>
<description>
Personal blog
</description>
<lastBuildDate>
Wed, 01 Jun 2016 10:19:23 +0300
</lastBuildDate>
<generator>
clj-rss
</generator>
<item>
<guid>
http://serce.me/posts/01-06-2016-wild-panama/
</guid>
<link>
http://serce.me/posts/01-06-2016-wild-panama/
</link>
<title>
Pure assembly in the forest of Panama
</title>
<description>
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Hi!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In this article,  I’ll tell you about some internal features of Project Panama. You’ll find out
how to increase the performance of your Java program using a pure inline assembler.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph text-center&quot;&gt;
&lt;p&gt;&lt;span class=&quot;image&quot;&gt;&lt;img src=&quot;/img/wild-panama/panama.jpg&quot; alt=&quot;panama&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph text-center&quot;&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;quoteblock&quot;&gt;
&lt;blockquote&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;We had two builds of jvm, seventy-five native functions, five sheets of high powered method handles, a Panama repository full of crazy features, and a whole galaxy of native data layouts, headers, compilers, optimizations&amp;#8230;&amp;#8203; and also a quart of heap, a case of wrappers, a pint of raw memory and two dozen AVX2 instructions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Not that we needed all that for the trip to Panama, but once you get locked into a serious jvm crash collection, the tendency is to push it as far as you can.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class=&quot;admonitionblock important&quot;&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class=&quot;icon&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Important&lt;/div&gt;
&lt;/td&gt;
&lt;td class=&quot;content&quot;&gt;
This article is written mostly about something that can never be released&lt;br&gt;
About API that can never be seen&lt;br&gt;
About code you shouldn&amp;#8217;t use in production&lt;br&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&quot;admonitionblock warning&quot;&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class=&quot;icon&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Warning&lt;/div&gt;
&lt;/td&gt;
&lt;td class=&quot;content&quot;&gt;
A lot of information in this article is based on my personal experiments with the internal state of Panama forest in June 2016, so it may be deprecated when you are reading it
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;So, let&amp;#8217;s begin our journey.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_welcome_to_panama&quot;&gt;Welcome to Panama&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;a href=&quot;http://openjdk.java.net/projects/panama/&quot;&gt;Panama&lt;/a&gt; is a new project under OpenJDK that tries to improve the connection between JVM and foreign APIs, including many interfaces commonly used by C programmers.
It is the missing piece in the Java ecosystem, a bridge between JAVA and native code.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The primary features that will be introduced in Project Panama are:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Native function calling and data access, respectfully, with huge JIT support (see &lt;a href=&quot;http://openjdk.java.net/jeps/191&quot;&gt;JEP191&lt;/a&gt;)&lt;br&gt;
(Similar problems but without huge runtime support can be solved using JNR as explained here &lt;a href=&quot;/posts/22-06-2015-jnr-fuse/&quot;&gt;previous article&lt;/a&gt;)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;New data layouts&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Special tools for wrapping native libraries&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The full overview of the problems that Panama tries to solve can be found here: &lt;a href=&quot;https://blogs.oracle.com/jrose/entry/the_isthmus_in_the_vm&quot;&gt;blog post&lt;/a&gt; (written by John Rose).
But some features in the mercurial forest of Project Panama don&amp;#8217;t really belong to JEP 191. These features are Vector API and Machine Code Snippets.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Last December, Vladimir Ivanov, one of the core contributors of Panama project made a commit where he introduced an ability to call a snippet of machine code in runtime&amp;#8230;&amp;#8203;
&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Project Panama: Machine code snippets and vector values support in HotSpot JVM &lt;a href=&quot;https://t.co/lW9GvKKk5h&quot;&gt;https://t.co/lW9GvKKk5h&lt;/a&gt; &lt;a href=&quot;https://twitter.com/hashtag/java?src=hash&quot;&gt;#java&lt;/a&gt;&lt;/p&gt;&amp;mdash; Vladimir Ivanov (@iwan0www) &lt;a href=&quot;https://twitter.com/iwan0www/status/672824680227708928&quot;&gt;December 4, 2015&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;br&gt;
This is an amazing feature, you can make an inline assembler call, crazy stuff&amp;#8230;&amp;#8203; It’s like the new Unsafe, but even cooler!
It’s like writing your own intrinsic, but in runtime. In this post I&amp;#8217;ll be primarily focused on Machine Code Snippets. So let&amp;#8217;s explore this opportunity.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_the_edge_of_the_forest&quot;&gt;The edge of the forest&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The first program that every programmer writes in a new language is &quot;Hello, World!&quot;. But it’s assembler, and it is called from Java. So let&amp;#8217;s make it simple.&lt;br&gt;
For example, an A+B+C function looks like this in each:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Plain Java&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;public static int sum(int a, int b, int c) {
    return a + b + c;
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;X86 assembly&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-x86asm&quot; data-lang=&quot;x86asm&quot;&gt;...
mov rax, rsi ; res = arg1
add rax, rdi ; res += arg2
add rax, rdx ; res += arg3
...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;CodeSnippet&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;static final MethodHandle sum3 = jdk.internal.panama.CodeSnippet.make(
            &quot;sum3&quot;, MethodType.methodType(int.class,/*result*/
                                          int.class /*rdi*/,
                                          int.class /*rsi*/,
                                          int.class /*rdx*/),
            true, /* isSupported */
            0x48, 0x89, 0xF0, // mov    rax,rsi
            0x48, 0x01, 0xF8, // add    rax,rdi
            0x48, 0x01, 0xD0  // add    rax,rdx
    );&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Here we used &lt;code&gt;jdk.internal.panama.CodeSnippet&lt;/code&gt; class to get MethodHandle to native code. And yes, this package is functionally important, it actually means internal API, so you very probably won&amp;#8217;t be able to use it.&lt;br&gt;
As an &lt;a href=&quot;http://hg.openjdk.java.net/panama/panama/hotspot/file/6818b4b2e922/src/cpu/x86/vm/sharedRuntime_x86_64.cpp#l1141&quot;&gt;arguments&lt;/a&gt; of &lt;code&gt;MethodType#methodType&lt;/code&gt; you can pass primitives and some special classes like &lt;code&gt;Long2&lt;/code&gt; (128 bit register), &lt;code&gt;Long4&lt;/code&gt;  (256 bit register) and &lt;code&gt;Long8&lt;/code&gt; (512 bit register).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Based on what you’ve seen above, you could say that we were able to use JNI before, so what’s the point of using inline ASM? This is true, but the thing is the C2 compiler can easily inline the code snippet. So, it gives you an opportunity (if you’re crazy enough) to write your own JVM intrinsic without coding it in the JVM.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Let&amp;#8217;s compare assembly produced by the JVM after compiling and inlining for every method.&lt;/p&gt;
&lt;/div&gt;
&lt;table class=&quot;tableblock frame-all grid-cols spread fit-table&quot;&gt;
&lt;colgroup&gt;
&lt;col style=&quot;width: 33.3333%;&quot;&gt;
&lt;col style=&quot;width: 33.3333%;&quot;&gt;
&lt;col style=&quot;width: 33.3334%;&quot;&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th class=&quot;tableblock halign-left valign-top&quot;&gt;Plain Java&lt;/th&gt;
&lt;th class=&quot;tableblock halign-left valign-top&quot;&gt;CodeSnippet ASM&lt;/th&gt;
&lt;th class=&quot;tableblock halign-left valign-top&quot;&gt;JNI&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;div&gt;&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-x86asm&quot; data-lang=&quot;x86asm&quot;&gt;[Verified Entry Point]
 sub  rsp,0x18
 mov  QWORD PTR [rsp+0x10],rbp  ;*synch entry

jitresult:
 mov  eax,DWORD PTR [rsi+0x1c]
 add  eax,DWORD PTR [rsi+0x18]
 add  eax,DWORD PTR [rsi+0x20]  ;*iadd


exit:
 add  rsp,0x10
 pop  rbp
 test DWORD PTR [rip+0x15b4ea60],eax&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/td&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;div&gt;&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-x86asm&quot; data-lang=&quot;x86asm&quot;&gt;[Verified Entry Point]
 sub  rsp,0x18
 mov  QWORD PTR [rsp+0x10],rbp;*sync entry
 mov  r10,rsi
 mov  esi,DWORD PTR [rsi+0x1c] ;*field b
 mov  edx,DWORD PTR [r10+0x20] ;*field c
 mov  edi,DWORD PTR [r10+0x18] ;*field a

snippet:
 mov  rax,rsi
 add  rax,rdi
 add  rax,rdx

exit:
 add  rsp,0x10
 pop  rbp
 test DWORD PTR [rip+0x16d21852],eax&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/td&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;div&gt;&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-x86asm&quot; data-lang=&quot;x86asm&quot;&gt;[Verified Entry Point]
 mov  DWORD PTR [rsp-0x14000],eax
 push rbp
 sub  rsp,0x10           ;*sync entry

 mov  edx,DWORD PTR [rsi+0x1c]  ;*field b
 mov  ecx,DWORD PTR [rsi+0x20]  ;*field c
 mov  esi,DWORD PTR [rsi+0x18]  ;*field a

native_call:
 xchg ax,ax
 call 0x00007f7ab5668738

exit:
 add  rsp,0x10
 pop  rbp
 test DWORD PTR [rip+0x166add39],eax
 ret  ;*invokestatic s_nat

runtime_call_rethrow_Java:
 mov    rsi,rax
 add    rsp,0x10
 pop    rbp
 jmp    0x00007f7aadc7b6e0&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As you can see here the only difference between the C2 JIT version and our CodeSnippet is the movement of arguments between registers to satisfy calling convention. And the C2 perfectly inlined exactly the same piece of code as shown above. At the same time, JNI performs a real native call.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;But what’s the point of writing inline asm snippets in Java? Usually there is no reason to do so, the C2 is able to compile your code into something that works much faster. But there are several things that the C2 can’t do efficiently. The most important is that the C2 can’t rewrite your algorithm using SIMD operations yet.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_go_deeper_to_hidden_places&quot;&gt;Go deeper to hidden places&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Usually our applications are not about A+B+C functions, but about some real code. And our applications can contain, say, the function that calculates checksums of buffers. A perfectly real task, that you can encounter in different kinds of software.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Let&amp;#8217;s imagine our application has a little function called checksum that makes a sum of bytes in the buffer and gives us hash [0, 256) as a result.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Here’s the code:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;private static int checksumPlainJava(ByteBuffer buffer, int size) {
    int checksum = 0;
    for (int i = 0; i &amp;lt; size; ++i) {
        checksum += buffer.get(i);
    }
    // make it unsigned first to avoid negative result
    return (int) (Integer.toUnsignedLong(checksum) % 256);
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In our application we operate big byte buffers and we have to calculate checksums very often. We discovered that this checksum function is our bottleneck. And we need to optimize it. What options do we have?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_jni&quot;&gt;JNI&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;You may see on the last line the ugly operation where we are trying to convert our signed int to unsigned to get the proper result. Of course, it’s the bottleneck you might think, isn&amp;#8217;t it? The cool C++ has unsigned variables - let&amp;#8217;s make a JNI call!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Ok, here we go, C++ code:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;JNI checksum&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-cpp&quot; data-lang=&quot;cpp&quot;&gt;JNIEXPORT jint JNICALL Java_me_serce_panex_ChecksumBenchmark_nativePlainChecksum
    (JNIEnv * env, jclass clz, jlong addr, jint targetLength) {
    char *target = reinterpret_cast&amp;lt;char *&amp;gt;(addr);
    unsigned int checksum = 0;
    for (int i = 0; i &amp;lt; targetLength; ++i) {
        checksum += (unsigned int) target[i];
    }
    return checksum % 256;
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Now we have to check the performance. We may expect incredible results. For performance measurement we will be using &lt;a href=&quot;http://openjdk.java.net/projects/code-tools/jmh/&quot;&gt;JMH&lt;/a&gt;, the de-facto standard in Java benchmarking. You can find a great deal of articles answering the question &quot;why JMH?&quot; on the internet.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;There is no way to get a native memory address for DirectByteBuffer, so we are using reflection trick here to get the field that contains this address. Now we’re able to access memory from C++ code directly. We’re checking how fast the function is in case of &lt;em&gt;4&lt;/em&gt;/&lt;em&gt;8096&lt;/em&gt;/&lt;em&gt;129536&lt;/em&gt; size buffers.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Benchmark setup&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;private ByteBuffer buffer;
private long address = 0;

@Param({&quot;4&quot;, &quot;8096&quot;, &quot;129536&quot;})
private int size = 4;

public static long getAddress(ByteBuffer buffy) throws Throwable {
    Field address = Buffer.class.getDeclaredField(&quot;address&quot;);
    address.setAccessible(true);
    return address.getLong(buffy);
}

@Setup
public void setup() throws Throwable {
    buffer = ByteBuffer.allocateDirect(size).order(ByteOrder.nativeOrder());
    ThreadLocalRandom random = ThreadLocalRandom.current();
    for (int i = 0; i &amp;lt; size / 4; i++) {
        buffer.putInt(random.nextInt());
    }
    address = getAddress(buffer);
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;literalblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;And the results&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;Benchmark                       (size)  Mode  Cnt   Score    Error  Units
ChecksumBenchmark.JNI_Checksum       4  avgt    3   0.009 ±  0.001  us/op
ChecksumBenchmark.JNI_Checksum    8096  avgt    3   3.085 ±  0.039  us/op
ChecksumBenchmark.JNI_Checksum  129536  avgt    3  48.879 ±  5.655  us/op
ChecksumBenchmark.plainJava          4  avgt    3   0.006 ±  0.001  us/op
ChecksumBenchmark.plainJava       8096  avgt    3   2.190 ±  0.834  us/op
ChecksumBenchmark.plainJava     129536  avgt    3  34.452 ±  3.341  us/op&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As you can see, the JNI loop is slower. But what happened? Could it mean that JNI is really slow? As we saw earlier CodeSnippet is faster. So we can try the same with code, but written using CodeSnippet!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;However, it may be hard to write code in pure machine codes, so we can make it another way. We can write C++ code; then compile it, open it in a hex editor and put the machine code into our method. Sounds creepy, but it’s possible.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Several things you should be careful about:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;You shouldn&amp;#8217;t have a ret instruction, JVM will take care of it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You should look carefully through your assembly code to be sure that it doesn&amp;#8217;t try to access outside memory using an outside method.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;And, finally, you should be careful about calling convention&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Typical &lt;code&gt;ls&lt;/code&gt; picture that you can see get after several experiments&lt;/div&gt;
&lt;p&gt;&lt;span class=&quot;image&quot;&gt;&lt;img src=&quot;/img/wild-panama/crashes.png&quot; alt=&quot;crashes&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Here’s the code and we’re ready to run benchmark again&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;static final MethodHandle codeSnippetChecksum = jdk.internal.panama.CodeSnippet.make(
        &quot;checksum&quot;, MethodType.methodType(int.class, long.class, int.class),
        isX64(),
        0x48, 0x85, 0xF6, 0x74, 0x1E, 0x48, 0x01, 0xFE, 0x31, 0xC0, 0x66, 0x0F, 0x1F, 0x44,
        0x00, 0x00, 0x0F, 0xBE, 0x17, 0x48, 0x83, 0xC7, 0x01, 0x01, 0xD0, 0x48, 0x39, 0xF7,
        0x75, 0xF2, 0x0F, 0xB6, 0xC0, 0xEB, 0x02, 0x31, 0xC0);

@Benchmark
public int codeSnippetChecksum() throws Throwable {
    return (int) plainC_O2.invoke(address, size);
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;literalblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Result&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;Benchmark                              (size)  Mode  Cnt   Score    Error  Units
ChecksumBenchmark.JNI_Checksum              4  avgt    4   0.008 ±  0.001  us/op
ChecksumBenchmark.JNI_Checksum           8096  avgt    4   3.060 ±  0.056  us/op
ChecksumBenchmark.JNI_Checksum         129536  avgt    4  49.865 ±  2.135  us/op
ChecksumBenchmark.codeSnippetChecksum       4  avgt    4   0.005 ±  0.001  us/op
ChecksumBenchmark.codeSnippetChecksum    8096  avgt    4   2.806 ±  0.243  us/op
ChecksumBenchmark.codeSnippetChecksum  129536  avgt    4  48.911 ±  0.448  us/op
ChecksumBenchmark.plainJava                 4  avgt    4   0.006 ±  0.001  us/op
ChecksumBenchmark.plainJava              8096  avgt    4   2.163 ±  0.035  us/op
ChecksumBenchmark.plainJava            129536  avgt    4  34.414 ±  0.984  us/op&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;And finally, you can observe pretty much the same results. The only noticeable difference is for buffers that have a very small size. And even the CodeSnippet version is slower than the code produced by JIT.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The key is I used -O2 GCC option, which doesn&amp;#8217;t perform a lot of interesting optimizations.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;literalblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;g++ -shared -fpic  -Wall -O2   -I/usr/include ... checksum.c -o libchecksum.so&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;And as a result, GCC didn&amp;#8217;t perform well, and we&amp;#8217;ve got an almost literal translation of that we wrote in C++ to assembly. At the same time, JIT gave us a good unrolled loop.&lt;/p&gt;
&lt;/div&gt;
&lt;table class=&quot;tableblock frame-all grid-cols spread&quot;&gt;
&lt;colgroup&gt;
&lt;col style=&quot;width: 50%;&quot;&gt;
&lt;col style=&quot;width: 50%;&quot;&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th class=&quot;tableblock halign-left valign-top&quot;&gt;JIT&lt;/th&gt;
&lt;th class=&quot;tableblock halign-left valign-top&quot;&gt;GCC O2&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;div&gt;&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-x86asm&quot; data-lang=&quot;x86asm&quot;&gt;....
loop:
 movsx  r10d,BYTE PTR [rbp+0x7]
 movsx  r8d,BYTE PTR [rbp+0x6]
 movsx  r11d,BYTE PTR [rbp+0x5]
 movsx  ebx,BYTE PTR [rbp+0x4]
 movsx  ecx,BYTE PTR [rbp+0x3]
 movsx  edx,BYTE PTR [rbp+0x2]
 movsx  edi,BYTE PTR [rbp+0x1]
 movsx  ebp,BYTE PTR [rbp+0x0]
 add    eax,ebp
 add    eax,edi
 add    eax,edx
 add    eax,ecx
 add    eax,ebx
 add    eax,r11d
 add    eax,r8d
 add    eax,r10d
 add    r9d,0x8 ; i+= 8
 cmp    r9d,r13d
 jl     loop  ;*if_icmpge
....&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/td&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;div&gt;&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-x86asm&quot; data-lang=&quot;x86asm&quot;&gt;...
loop:
 movsx  edi,BYTE PTR [rsi+rdx*1]
 add    rsi,0x1 ; i+= 1
 add    eax,edi
 cmp    ecx,esi ; if return
 jg     loop
 ...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;So, we can use -O3 if we need more optimizations.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;literalblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;With -03&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;Benchmark                                (size)  Mode  Cnt   Score    Error  Units
ChecksumBenchmark.JNI_Checksum                4  avgt    4   0.009 ±  0.001  us/op
ChecksumBenchmark.JNI_Checksum             8096  avgt    4   3.089 ±  0.066  us/op
ChecksumBenchmark.JNI_Checksum           129536  avgt    4  49.481 ±  2.071  us/op
ChecksumBenchmark.codeSnippetChecksum         4  avgt    4   0.005 ±  0.001  us/op
ChecksumBenchmark.codeSnippetChecksum      8096  avgt    4   2.784 ±  0.153  us/op
ChecksumBenchmark.codeSnippetChecksum    129536  avgt    4  49.350 ±  2.208  us/op
ChecksumBenchmark.codeSnippetChecksumO3       4  avgt    4   0.006 ±  0.001  us/op
ChecksumBenchmark.codeSnippetChecksumO3    8096  avgt    4   0.621 ±  0.022  us/op
ChecksumBenchmark.codeSnippetChecksumO3  129536  avgt    4   9.672 ±  0.201  us/op
ChecksumBenchmark.plainJava                   4  avgt    4   0.006 ±  0.001  us/op
ChecksumBenchmark.plainJava                8096  avgt    4   2.161 ±  0.089  us/op
ChecksumBenchmark.plainJava              129536  avgt    4  34.825 ±  1.178  us/op&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;There is a simple explanation why GCC -03 version is faster than code emitted by JIT. Here GCC was able to vectorize our loop. So, it used SIMD instructions which gave our processor an ability to &quot;parallelize&quot; execution.&lt;/p&gt;
&lt;/div&gt;
&lt;table class=&quot;tableblock frame-all grid-cols spread&quot;&gt;
&lt;colgroup&gt;
&lt;col style=&quot;width: 50%;&quot;&gt;
&lt;col style=&quot;width: 50%;&quot;&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th class=&quot;tableblock halign-left valign-top&quot;&gt;JIT&lt;/th&gt;
&lt;th class=&quot;tableblock halign-left valign-top&quot;&gt;GCC O3&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;div&gt;&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-x86asm&quot; data-lang=&quot;x86asm&quot;&gt;....
loop:
 movsx  r10d,BYTE PTR [rbp+0x7]
 movsx  r8d,BYTE PTR [rbp+0x6]
 movsx  r11d,BYTE PTR [rbp+0x5]
 movsx  ebx,BYTE PTR [rbp+0x4]
 movsx  ecx,BYTE PTR [rbp+0x3]
 movsx  edx,BYTE PTR [rbp+0x2]
 movsx  edi,BYTE PTR [rbp+0x1]
 movsx  ebp,BYTE PTR [rbp+0x0]
 add    eax,ebp
 add    eax,edi
 add    eax,edx
 add    eax,ecx
 add    eax,ebx
 add    eax,r11d
 add    eax,r8d
 add    eax,r10d
 add    r9d,0x8 ; i+= 8
 cmp    r9d,r13d
 jl     loop  ;*if_icmpge
....&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/td&gt;
&lt;td class=&quot;tableblock halign-left valign-top&quot;&gt;&lt;div&gt;&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-x86asm&quot; data-lang=&quot;x86asm&quot;&gt;....
loop:
 add          r11, 0x1
 add          r8, 0x20
 cmp          r10, r11
 vpmovsxbw    ymm2, xmm1
 vextracti128 xmm1, ymm1, 0x1
 vpmovsxwd    ymm3, xmm2
 vextracti128 xmm2, ymm2, 0x1
 vpmovsxbw    ymm1, xmm1
 vpaddd       ymm0, ymm3, ymm0
 vpmovsxwd    ymm2, xmm2
 vpaddd       ymm0, ymm2, ymm0
 vpmovsxwd    ymm2, xmm1
 vextracti128 xmm1, ymm1, 0x1
 vpaddd       ymm0, ymm2, ymm0
 vpmovsxwd    ymm1, xmm1
 vpaddd       ymm0, ymm1, ymm0
 ja           loop
....&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;But that if we need more performance? Can we do it better than GCC?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_simd&quot;&gt;SIMD&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;It is possible to write the same code, but using AVX2 (256 byte registers) instructions. (Thanks, &lt;a href=&quot;https://twitter.com/kellylittlepage&quot;&gt;@kellylittlepage&lt;/a&gt;, for an &lt;a href=&quot;https://www.klittlepage.com/2013/12/10/accelerated-fix-processing-via-avx2-vector-instructions/&quot;&gt;awesome article&lt;/a&gt; where I&amp;#8217;ve read how to do it).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;C++ function that will be compiled and putted in CodeSnippet&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-cpp&quot; data-lang=&quot;cpp&quot;&gt;int avxChecksumAVX2(const char *const target, size_t targetLength) {
    const __m256i zeroVec = _mm256_setzero_si256();
    short d[16] = {1, 1, 1, 1, 1, 1, 1, 1,
                   1, 1, 1, 1, 1, 1, 1, 1};
    const __m256i oneVec = *((__m256i *) d);
    __m256i accum = _mm256_setzero_si256();
    unsigned int checksum = 0;
    size_t offset = 0;

    if (targetLength &amp;gt;= 32) {
        for (; offset &amp;lt;= targetLength - 32; offset += 32) {
            __m256i vec = _mm256_loadu_si256(
                    reinterpret_cast&amp;lt;const __m256i *&amp;gt;(target + offset));
            __m256i vl = _mm256_unpacklo_epi8(vec, zeroVec);
            __m256i vh = _mm256_unpackhi_epi8(vec, zeroVec);

            accum = _mm256_add_epi32(accum, _mm256_madd_epi16(vl, oneVec));
            accum = _mm256_add_epi32(accum, _mm256_madd_epi16(vh, oneVec));
        }
    }

    for (; offset &amp;lt; targetLength; ++offset) {
        checksum += (int) target[offset];
    }

    accum = _mm256_add_epi32(accum, _mm256_srli_si256(accum, 4));
    accum = _mm256_add_epi32(accum, _mm256_srli_si256(accum, 8));
    return (_mm256_extract_epi32(accum, 0) + _mm256_extract_epi32(accum, 4) +
            checksum) % 256;
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This is how a simple checksum function looks like after rewriting for vectorizing execution. Here, some GCC intrinsics like &lt;code&gt;&lt;a href=&quot;https://software.intel.com/en-us/node/524002&quot;&gt;_mm256_unpacklo_epi8&lt;/a&gt;&lt;/code&gt; and &lt;code&gt;&lt;a href=&quot;https://software.intel.com/en-us/node/513929&quot;&gt;_mm256_add_epi32&lt;/a&gt;&lt;/code&gt; are used. GCC has a special implementation for this functions that uses AVX2 instructions. Almost always it is just one instruction.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://software.intel.com/sites/landingpage/IntrinsicsGuide/&quot;&gt;Here&lt;/a&gt; you can find a full guide of Intel intrinsics&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This functions isn&amp;#8217;t so easy to understand, but how fast is it?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;literalblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Result&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;ChecksumBenchmark.JNI_Checksum                4  avgt    4   0.008 ±  0.001  us/op
ChecksumBenchmark.JNI_Checksum             8096  avgt    4   3.128 ±  0.024  us/op
ChecksumBenchmark.JNI_Checksum           129536  avgt    4  49.629 ±  0.694  us/op
ChecksumBenchmark.avx2Impl                    4  avgt    4   0.014 ±  0.001  us/op
ChecksumBenchmark.avx2Impl                 8096  avgt    4   0.239 ±  0.018  us/op
ChecksumBenchmark.avx2Impl               129536  avgt    4   4.128 ±  0.052  us/op
ChecksumBenchmark.codeSnippetChecksum         4  avgt    4   0.005 ±  0.001  us/op
ChecksumBenchmark.codeSnippetChecksum      8096  avgt    4   2.795 ±  0.044  us/op
ChecksumBenchmark.codeSnippetChecksum    129536  avgt    4  49.656 ±  0.733  us/op
ChecksumBenchmark.codeSnippetChecksumO3       4  avgt    4   0.006 ±  0.001  us/op
ChecksumBenchmark.codeSnippetChecksumO3    8096  avgt    4   0.630 ±  0.004  us/op
ChecksumBenchmark.codeSnippetChecksumO3  129536  avgt    4   9.810 ±  0.100  us/op
ChecksumBenchmark.plainJava                   4  avgt    4   0.006 ±  0.001  us/op
ChecksumBenchmark.plainJava                8096  avgt    4   2.224 ±  0.122  us/op
ChecksumBenchmark.plainJava              129536  avgt    4  35.042 ±  0.252  us/op&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Awesome it is 8x times faster than our original code.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;_java_way&quot;&gt;Java way&lt;/h4&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Let&amp;#8217;s say, now we met our performance requirements, but can we make it more readable than just an ugly blob of ASM code produced by GCC? It is possible to save the main loop inside Java and use Long4 vectors to pass data.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Java version of that scary function&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;public class VectorIntrinsics {
    ...
    private static final MethodHandle _mm256_loadu_si256 = jdk.internal.panama.CodeSnippet.make(
            &quot;_mm256_loadu_si256&quot;, MethodType.methodType(Long4.class, long.class),
            true,
            0xC5, 0xFE, 0x6F, 0x06 // vmovdqu ymm0, YMMWORD PTR [rdi]
    );
    public static Long4 _mm256_loadu_si256(long address) throws Throwable {
        return (Long4) _mm256_loadu_si256.invoke(address);
    }
    ...
}

private static int JAVA_avxChecksumAVX2(ByteBuffer buffer, long target, int targetLength)
    throws Throwable {
        Long4 zeroVec = Long4.ZERO;
        Long4 oneVec = ones;
        Long4 accum = Long4.ZERO;
        int checksum = 0;
        int offset = 0;

        if (targetLength &amp;gt;= 32) {
            for (; offset &amp;lt;= targetLength - 32; offset += 32) {
                Long4 vec = _mm256_loadu_si256(target + offset);
                Long4 vl = _mm256_unpacklo_epi8(vec, zeroVec);
                Long4 vh = _mm256_unpackhi_epi8(vec, zeroVec);

                accum = _mm256_add_epi32(accum, _mm256_madd_epi16(vl, oneVec));
                accum = _mm256_add_epi32(accum, _mm256_madd_epi16(vh, oneVec));
            }
        }

        for (; offset &amp;lt; targetLength; ++offset) {
            checksum += (int) buffer.get(offset);
        }

        accum = _mm256_add_epi32(accum, _mm256_srli_si256_4(accum));
        accum = _mm256_add_epi32(accum, _mm256_srli_si256_8(accum));
        long finalChecksum = _mm256_extract_epi32_0(accum) + _mm256_extract_epi32_4(accum)
                        + checksum;
        return (int) (Integer.toUnsignedLong((int) finalChecksum) % 256);
    }&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Now it is written in the right way. We wrote a lot of small methods; every method represents one small AVX2 instruction. And the main loop is written in Java. This code is reusable; it is much easier to write and understand than trying to write one big ASM blob. But, a big surprise, it is much slower then an ugly ASM blob.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;And again, JMH will help us to find answer with gc profiler.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;literalblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;That&amp;#8217;s why&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;JAVA_avx2Impl                                129536  avgt    4      30.394 ±     6.813   us/op
JAVA_avx2Impl:·gc.alloc.rate                 129536  avgt    4         NaN              MB/sec
JAVA_avx2Impl:·gc.count                      129536  avgt    4      34.000              counts
JAVA_avx2Impl:·gc.time                       129536  avgt    4      39.000                  ms
avx2Impl                                     129536  avgt    4       4.192 ±     0.246   us/op
avx2Impl:·gc.alloc.rate                      129536  avgt    4         NaN              MB/sec
avx2Impl:·gc.count                           129536  avgt    4         ≈ 0              counts&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;code&gt;JAVA_avxChecksumAVX2&lt;/code&gt; produces high allocation rate. Despite the fact that vector types work with escape analysis really well, this loop breaks our hopes. Because Long4 is immutable, we have to save &lt;code&gt;accum&lt;/code&gt; to the same variable on every loop iteration. Escape analysis can&amp;#8217;t understand this and we are getting a lot of allocations of boxed vector values.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Problematic code for Escape Analysis&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;Long accum = Long4.ZERO;
for (; offset &amp;lt;= targetLength - 32; offset += 32) {
    Long4 vec = _mm256_loadu_si256(target + offset);
    accum = operation(accum, vec); // EA, you are drunk, go home
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This problem is known issue. Very probably it will be fixed soon, but how can it be solved now?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As a workaround, we may try to create a temporary buffer and use a pair of &lt;code&gt;_mm256_loadu_si256&lt;/code&gt; and &lt;code&gt;_mm256_storeu_si256&lt;/code&gt; instructions on every iteration. That intrinsics use &lt;code&gt;vmovdqu&lt;/code&gt; instruction to load/store register value to the memory.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;GC free solution&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;static final ByteBuffer tmpBuf = ...
...
for (; offset &amp;lt;= targetLength - 32; offset += 32) {
    Long4 vec = _mm256_loadu_si256(target + offset);
    Long4 accum = _mm256_loadu_si256(tmpBuffAddr);
    Long4 result = operation(accum, vec);
    _mm256_storeu_si256(tmpBuffAddr, result);
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;literalblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Results&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;Benchmark                                       (size)  Mode  Cnt   Score   Error   Units
ChecksumBenchmark.JAVA_avx2Impl                 129536  avgt    4  23.837 ± 0.064   us/op
ChecksumBenchmark.JAVA_avx2Impl:·gc.alloc.rate  129536  avgt    4     NaN          MB/sec
ChecksumBenchmark.JAVA_avx2Impl:·gc.count       129536  avgt    4     ≈ 0          counts&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Now function is GC free; there is no garbage anymore and it is faster, but actually it&amp;#8217;s still quite slow. To understand why we should use a profiler, but simple solutions like Yourkit or JProfiler won&amp;#8217;t help us, we must work on instruction level. Thank goodness, JMH has an excellent support of perf profiler, you need just to pass an option to it (don&amp;#8217;t forget to install perf on your system before).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-x86asm&quot; data-lang=&quot;x86asm&quot;&gt; 12.39%   26.58%    vmovdqu YMMWORD PTR [rsp+0x40],ymm0
 12.88%    2.85%    movabs r10,0x6d61010e8
           0.01%    vmovdqu ymm1,YMMWORD PTR [r10+0x10]
  0.01%             vmovdqu ymm0,YMMWORD PTR [rsp+0x20]
                    vpunpcklbw ymm0,ymm0,ymm1
  4.42%    0.03%    movabs r10,0x6d61010b8
  0.01%             vmovdqu ymm1,YMMWORD PTR [r10+0x10]
  0.02%    0.01%    vpmaddwd ymm0,ymm0,ymm1
  0.02%    0.01%    vpmaddwd ymm0,ymm0,ymm1
           0.02%    vmovdqu ymm1,ymm0
  4.20%    2.95%    vmovdqu ymm0,YMMWORD PTR [rsp+0x40]
  8.45%   22.88%    vpaddd ymm0,ymm1,ymm0
 12.91%    5.79%    vmovdqu YMMWORD PTR [rsp+0x40],ymm0&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;As you can see, we are spending an enormous amount of time just to load out the temporary buffer and store it back just to avoid GC. So, we can rewrite algorithm a little bit instead. We&amp;#8217;ll be saving a final result to &lt;code&gt;checksum&lt;/code&gt; variable right in the loop instead of using it further in vector calculations.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Here the code&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;for (; offset &amp;lt;= targetLength - 32; offset += 32) {
    Long4 vec = _mm256_loadu_si256(target + offset);
    Long4 lVec = _mm256_unpacklo_epi8(vec, zeroVec);
    Long4 hVec = _mm256_unpackhi_epi8(vec, zeroVec);
    Long4 sum = _mm256_add_epi16(lVec, hVec);
    sum = _mm256_hadd_epi16(sum, sum);
    sum = _mm256_hadd_epi16(sum, sum);
    sum = _mm256_hadd_epi16(sum, sum);
    checksum += _mm256_extract_epi16_0(sum) + _mm256_extract_epi16_15(sum);
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;literalblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Benchmark results&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre&gt;Benchmark                        (size)  Mode  Cnt   Score    Error  Units
ChecksumBenchmark.JAVA_avx2Impl       4  avgt    4   0.005 ±  0.001  us/op
ChecksumBenchmark.JAVA_avx2Impl    8096  avgt    4   1.245 ±  0.028  us/op
ChecksumBenchmark.JAVA_avx2Impl  129536  avgt    4  20.095 ±  0.314  us/op
ChecksumBenchmark.avx2Impl            4  avgt    4   0.013 ±  0.001  us/op
ChecksumBenchmark.avx2Impl         8096  avgt    4   0.211 ±  0.004  us/op
ChecksumBenchmark.avx2Impl       129536  avgt    4   3.317 ±  0.077  us/op
ChecksumBenchmark.plainJava           4  avgt    4   0.005 ±  0.001  us/op
ChecksumBenchmark.plainJava        8096  avgt    4   2.109 ±  0.035  us/op
ChecksumBenchmark.plainJava      129536  avgt    4  33.503 ±  0.227  us/op&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This version of the code is even faster, but it can&amp;#8217;t achieve the performance of big ugly assembly blob yet because escape analysis is like a big stone on our way. However this code can be maintained easily, and this API is under active development; there are a lot of experiments happening right now. So, you will have fought this ugly blob when these features are released.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Moreover, all that machine snippets and direct Long* vector parameters are really low-level API. Prototypes of high-level API you can find &lt;a href=&quot;http://hg.openjdk.java.net/panama/panama/jdk/file/c5a104d33632/test/panama/vector-api-boxed-variant/src/test/java/com/oracle/vector/BytesLong2Test.java&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;http://hg.openjdk.java.net/panama/panama/jdk/file/c5a104d33632/test/panama/vector-api-patchable/src/test/java/SnippetTest.java&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;I think that&amp;#8217;s a perfect point to end a journey through the jungle of Panama. We have seen enough crazy things. I&amp;#8217;ll be glad to hear any comments from you. You can find all the experiments &lt;a href=&quot;https://github.com/SerCeMan/panama-article&quot;&gt;here&lt;/a&gt; (don&amp;#8217;t forget to build your own JDK before running the benchmarks). I&amp;#8217;ll be glad to hear any comments from you.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_conclusions&quot;&gt;Conclusions&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Project Panama will bring us great features, but these are likely to arrive much further down the line&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Nothing is impossible, even running an inline assembler from Java&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;There are a lot of features that can be done in Java with Vector API and Machine Code Snippets already, although it is only the beginning of the story.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Compiler can optimize your code really well, most probably better than you.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It is very important to measure performance while you are doing optimizations. Or else you can make it even worse.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Seeing how your code will work in the future will help you to better understand how it works now.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_thanks&quot;&gt;Thanks&lt;/h3&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://twitter.com/kellylittlepage&quot;&gt;@kellylittlepage&lt;/a&gt; for an awesome article about AVX instruction&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://twitter.com/harrigan_shane&quot;&gt;@harrigan_shane&lt;/a&gt; for comments about my writing style&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://twitter.com/iwan0www&quot;&gt;@iwan0www&lt;/a&gt; for comments and suggestions regarding this post&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You for reading it&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
<enclosure>

</enclosure>
<pubDate>
Wed, 01 Jun 2016 00:00:00 +0300
</pubDate>
</item>
<item>
<guid>
http://serce.me/posts/22-06-2015-jnr-fuse/
</guid>
<link>
http://serce.me/posts/22-06-2015-jnr-fuse/
</link>
<title>
JNR-FUSE: library for using FUSE from Java
</title>
<description>
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Hi!&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In this article, I&amp;#8217;ll tell you how to implement userspace file system using Java without a line of kernel space code.
I&amp;#8217;ll also show you how to connect Java and native code without writing C code and save maximum performance.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Originally, I posted this article on &lt;a href=&quot;https://habrahabr.ru/post/260801/&quot;&gt;habrahabr&lt;/a&gt; (in Russian).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;span class=&quot;image&quot;&gt;&lt;img src=&quot;/img/jnr-fuse/jackie.jpg&quot; alt=&quot;jackie&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_fuse&quot;&gt;FUSE&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;First of all, it is important to understand what FUSE is.
FUSE - FileSystem in Userspace - helps users without any privileges to create their file system without a necessity to write code in a kernel space.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This is possible because the filesystem code runs in userspace. And the FUSE module is just a bridge between the kernel API and your code. FUSE was officially included in the Linux source tree in 2.6.14.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;span class=&quot;image&quot;&gt;&lt;img src=&quot;/img/jnr-fuse/bridge.png&quot; alt=&quot;bridge&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;So, you can easily create your own filesystem (&lt;a href=&quot;https://github.com/libfuse/libfuse/blob/master/example/hello.c&quot;&gt;here is the simplest example&lt;/a&gt;). There are a lot of areas where you can use it. For example, you can quickly write a FS where Github or DropBox would be the backend.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Or, let&amp;#8217;s imagine, you have a business application where all user files are stored in a database. But your client wants to have access to them from a filesystem on the server. Of course to duplicate files in the filesystem and the database is the wrong decision. And here FUSE comes in; you just need a little FUSE program which handles all user requests to the directory and redirects them to the database.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_java_and_native_code&quot;&gt;Java and native code&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;So far so good. But implementation of FUSE starts from &quot;include header &amp;lt;fuse.h&amp;gt;&quot;. But your business application is written in Java. Obviously, it is necessary to communicate with the native code.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_jni&quot;&gt;JNI&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The standard tool for a native communication in Java is JNI. But it brings a lot of complexity. Especially because for using FUSE we need a lot of callbacks from the native code to Java. And &quot;write once&quot; is suffering in this case (However, in the case of FUSE it is not so important).
If you try to find projects that implement a FUSE wrapper using JNI you will find a few projects, but they have been obsolete for a long time. And their API is very inconvenient.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_jna&quot;&gt;JNA&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Another option is &lt;a href=&quot;https://github.com/java-native-access/jna&quot;&gt;JNA library&lt;/a&gt;.  JNA (Java Native Access) gives you the possibility to get access to the native code easily without using JNI only by using Java code. It is very easy; you just need to declare an interface which matches the native code and get an implementation through &quot;Native.loadLibrary&quot;. And that&amp;#8217;s all.
Another advantage of JNA is very detailed documentation. The project is alive, and it is in active development.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Moreover, a good project implementing FUSE using JNA already exists.
But JNA has a lot of problems with performance. JNA is reflection based, so jumping from native code to Java code with data conversion is very expensive. It is not so important if native calls are rare. But a FS has a lot of native calls. The only way to speed up fuse-jna is to read files using big chunks, but it doesn&amp;#8217;t always work. For example, when you have no access to a client&amp;#8217;s code or when all files are small.
Obviously, we need a library that combines JNI performance and JNA convenience.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_jnr&quot;&gt;JNR&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;And here is where JNR (Java Native Runtime) comes in. JNR, like JNA, is based on libffi library, but it uses a bytecode generation instead of reflection. And as a result, JNR achieves excellent performance.
The information about JNR is very limited. The most detailed piece of information is &lt;a href=&quot;http://medianetwork.oracle.com/video/player/2630340184001&quot;&gt;Charles Nutter&amp;#8217;s talk on JVMLS 2013&lt;/a&gt;. But despite the lack of information, JNR is already a big ecosystem actively used by JRuby. A lot of jnr-based libraries such as unix-sockets and posix-api are actively used by different projects.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;span class=&quot;image&quot;&gt;&lt;img src=&quot;/img/jnr-fuse/jnr.png&quot; alt=&quot;jnr&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;JNR is a library which became a basis for the development of &lt;a href=&quot;http://openjdk.java.net/jeps/191&quot;&gt;JEP 191 - Foreign Function Interface&lt;/a&gt;, which is targeted for Java 10.
In comparison to JNA, JNR has no proper documentation, and you need to look for answers in the source code. That is the main reason for this mini-guide.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_specialties_of_writing_code_using_java_native_runtime&quot;&gt;Specialties of writing code using Java Native Runtime&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_function_binding&quot;&gt;Function binding&lt;/h3&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;The simplest binding&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;import jnr.ffi.*;
import jnr.ffi.types.pid_t;

/**
 * Gets the process ID of the current process, and that of its parent.
 */
public class Getpid {
    public interface LibC  {
        public @pid_t long getpid();
        public @pid_t long getppid();
    }

    public static void main(String[] args) {
        LibC libc = LibraryLoader.create(LibC.class).load(&quot;c&quot;);

        System.out.println(&quot;pid=&quot; + libc.getpid() + &quot; parent pid=&quot; + libc.getppid());
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Here we are the loading java library which matches the native interface by name.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In the case of FUSE, we need an interface with method fuse_main_real where FuseOperations structure with all callbacks passes as an argument.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;public interface LibFuse {
    int fuse_main_real(int argc, String argv[], FuseOperations op, int op_size, Pointer user_data);
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_implementation_of_structures&quot;&gt;Implementation of structures&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Often you need to work with structure which is located at a certain address, for example with fuse_bufvec structure:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct fuse_bufvec {
    size_t count;
    size_t idx;
    size_t off;
    struct fuse_buf buf[1];
};&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;For its implementation, we need to make a successor of jnr.ffi.Struct.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;import jnr.ffi.*;

public class FuseBufvec extends Struct {
    public FuseBufvec(jnr.ffi.Runtime runtime) {
        super(runtime);
    }
    public final size_t count = new size_t();
    public final size_t idx = new size_t();
    public final size_t off = new size_t();
    public final FuseBuf buf = inner(new FuseBuf(getRuntime()));
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;After that, you have to set proper callback implementation into the getattr field.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;fuseOperations.getattr.set((path, stbuf) -&amp;gt; 0);&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_enum&quot;&gt;Enum&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Enum implementation is not so obvious as other parts of the library.
You need to inherit your enum from jnr.ffi.util.EnumMapper.IntegerEnum and implement method intValue&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;enum fuse_buf_flags {
    FUSE_BUF_IS_FD    = (1 &amp;lt;&amp;lt; 1),
    FUSE_BUF_FD_SEEK    = (1 &amp;lt;&amp;lt; 2),
    FUSE_BUF_FD_RETRY    = (1 &amp;lt;&amp;lt; 3),
};&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;public enum FuseBufFlags implements EnumMapper.IntegerEnum {
    FUSE_BUF_IS_FD(1 &amp;lt;&amp;lt; 1),
    FUSE_BUF_FD_SEEK(1 &amp;lt;&amp;lt; 2),
    FUSE_BUF_FD_RETRY(1 &amp;lt;&amp;lt; 3);

    private final int value;

    FuseBufFlags(int value) {
        this.value = value;
    }

    @Override
    public int intValue() {
        return value;
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_work_with_memory&quot;&gt;Work with memory&lt;/h3&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;For working with direct memory wrapper jnr.ffi.Pointer exists.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You can allocate memory using jnr.ffi.Memory&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The entry point of JNR API learning is jnr.ffi.Runtime&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;This knowledge is enough to implement a simple cross-platform wrapper for some native library.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;_jnr_fuse&quot;&gt;JNR-FUSE&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;What I&amp;#8217;ve implemented is a FUSE wrapper in my project jnr-fuse. Previously I used fuse-jna, but it was a bottleneck in the FS implementation. During the development, I tried to save compatibility with the native interface (&amp;lt;fuse.h&amp;gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;For implementing your own file system, you need to extend ru.serce.jnrfuse.FuseStubFS and implement several methods.
Fuse_operations contain &lt;a href=&quot;http://fuse.sourcearchive.com/documentation/2.8.4-1.4ubuntu1/structfuse__operations.html&quot;&gt;a lot of methods&lt;/a&gt;, but for getting your FS up and running, you just need to implement several methods.
It is very easy, &lt;a href=&quot;https://github.com/SerCeMan/jnr-fuse/tree/master/src/main/java/ru/serce/jnrfuse/examples&quot;&gt;here are some examples&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Currently, only Linux is supported (x86 and x64).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Library exists in JCenter.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Gradle&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-groovy&quot; data-lang=&quot;groovy&quot;&gt;repositories {
    jcenter()
}

dependencies {
    compile 'com.github.serceman:jnr-fuse:0.1'
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Maven&lt;/div&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-xml&quot; data-lang=&quot;xml&quot;&gt;    &amp;lt;repositories&amp;gt;
        &amp;lt;repository&amp;gt;
            &amp;lt;id&amp;gt;central&amp;lt;/id&amp;gt;
            &amp;lt;name&amp;gt;bintray&amp;lt;/name&amp;gt;
            &amp;lt;url&amp;gt;http://jcenter.bintray.com&amp;lt;/url&amp;gt;
        &amp;lt;/repository&amp;gt;
    &amp;lt;/repositories&amp;gt;

    &amp;lt;dependencies&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;com.github.serceman&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;jnr-fuse&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;0.1&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
    &amp;lt;/dependencies&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_jnr_fuse_and_fuse_jna_performance_comparison&quot;&gt;JNR-FUSE and FUSE-JNA performance comparison&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In my case the FS was read-only, and I was interested in throughput.
The performance will mostly depend on your FS implementation, so if you already use fuse-jna, you&amp;#8217;ll be able to change it easily to jnr-fuse, write a test, and to see the performance difference on your workload. (It will be helpful anyway because we all love to achieve new levels of performance, right?)&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In order to show performance the difference, I moved MemoryFS implementation from fuse-jna to jnr-fuse with minimal changes and ran a reading test. For the test, I used &lt;a href=&quot;http://freecode.com/projects/fio&quot;&gt;fio&lt;/a&gt; framework.&lt;/p&gt;
&lt;/div&gt;
&lt;details&gt;
  &lt;summary&gt;&lt;span style=&quot;color: #527bbd&quot;&gt;Test configuration&lt;/span&gt;&lt;/summary&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-properties&quot; data-lang=&quot;properties&quot;&gt;[readtest]
blocksize=4k
directory=/tmp/mnt/
rw=randread
direct=1
buffered=0
ioengine=libaio
time_based=60
size=16M
runtime=60&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;details&gt;
  &lt;summary&gt;&lt;span style=&quot;color: #527bbd&quot;&gt;The result of of fuse-jna&lt;/span&gt;&lt;/summary&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-none&quot; data-lang=&quot;none&quot;&gt;serce@SerCe-FastLinux:~/git/jnr-fuse/bench$ fio read.ini
readtest: (g=0): rw=randread, bs=4K-4K/4K-4K/4K-4K, ioengine=libaio, iodepth=1
fio-2.1.3
Starting 1 process
readtest: Laying out IO file(s) (1 file(s) / 16MB)
Jobs: 1 (f=1): [r] [100.0% done] [24492KB/0KB/0KB /s] [6123/0/0 iops] [eta 00m:00s]
readtest: (groupid=0, jobs=1): err= 0: pid=10442: Sun Jun 21 14:49:13 2015
read: io=1580.2MB, bw=26967KB/s, iops=6741, runt= 60000msec
slat (usec): min=46, max=29997, avg=146.55, stdev=327.68
clat (usec): min=0, max=69, avg= 0.47, stdev= 0.66
lat (usec): min=47, max=30002, avg=147.26, stdev=327.88
clat percentiles (usec):
| 1.00th=[ 0], 5.00th=[ 0], 10.00th=[ 0], 20.00th=[ 0],
| 30.00th=[ 0], 40.00th=[ 0], 50.00th=[ 0], 60.00th=[ 1],
| 70.00th=[ 1], 80.00th=[ 1], 90.00th=[ 1], 95.00th=[ 1],
| 99.00th=[ 2], 99.50th=[ 2], 99.90th=[ 3], 99.95th=[ 12],
| 99.99th=[ 14]
bw (KB /s): min=17680, max=32606, per=96.09%, avg=25913.26, stdev=3156.20
lat (usec): 2=97.95%, 4=1.96%, 10=0.02%, 20=0.06%, 50=0.01%
lat (usec): 100=0.01%
cpu: usr=1.98%, sys=5.94%, ctx=405302, majf=0, minf=28
IO depths: 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, &amp;gt;=64=0.0%
submit: 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &amp;gt;=64=0.0%
complete: 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &amp;gt;=64=0.0%
issued: total=r=404511/w=0/d=0, short=r=0/w=0/d=0

Run status group 0 (all jobs):
READ: io=1580.2MB, aggrb=26967KB/s, minb=26967KB/s, maxb=26967KB/s, mint=60000msec, maxt=60000msec&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;details&gt;
  &lt;summary&gt;&lt;span style=&quot;color: #527bbd&quot;&gt;The result of jnr-fuse&lt;/span&gt;&lt;/summary&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-properties&quot; data-lang=&quot;properties&quot;&gt;serce@SerCe-FastLinux:~/git/jnr-fuse/bench$ fio read.ini
readtest: (g=0): rw=randread, bs=4K-4K/4K-4K/4K-4K, ioengine=libaio, iodepth=1
fio-2.1.3
Starting 1 process
readtest: Laying out IO file(s) (1 file(s) / 16MB)
Jobs: 1 (f=1): [r] [100.0% done] [208.5MB/0KB/0KB /s] [53.4K/0/0 iops] [eta 00m:00s]
readtest: (groupid=0, jobs=1): err= 0: pid=10153: Sun Jun 21 14:45:17 2015
read: io=13826MB, bw=235955KB/s, iops=58988, runt= 60002msec
slat (usec): min=6, max=23671, avg=15.80, stdev=19.97
clat (usec): min=0, max=1028, avg= 0.37, stdev= 0.78
lat (usec): min=7, max=23688, avg=16.29, stdev=20.03
clat percentiles (usec):
| 1.00th=[ 0], 5.00th=[ 0], 10.00th=[ 0], 20.00th=[ 0],
| 30.00th=[ 0], 40.00th=[ 0], 50.00th=[ 0], 60.00th=[ 0],
| 70.00th=[ 1], 80.00th=[ 1], 90.00th=[ 1], 95.00th=[ 1],
| 99.00th=[ 1], 99.50th=[ 1], 99.90th=[ 2], 99.95th=[ 2],
| 99.99th=[ 10]
lat (usec): 2=99.88%, 4=0.10%, 10=0.01%, 20=0.01%, 50=0.01%
lat (usec): 100=0.01%, 250=0.01%
lat (msec): 2=0.01%
cpu: usr=9.33%, sys=34.01%, ctx=3543137, majf=0, minf=28
IO depths: 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, &amp;gt;=64=0.0%
submit: 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &amp;gt;=64=0.0%
complete: 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &amp;gt;=64=0.0%
issued: total=r=3539449/w=0/d=0, short=r=0/w=0/d=0

Run status group 0 (all jobs):
READ: io=13826MB, aggrb=235955KB/s, minb=235955KB/s, maxb=235955KB/s, mint=60002msec, maxt=60002msec&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;span class=&quot;image&quot;&gt;&lt;img src=&quot;/img/jnr-fuse/table.png&quot; alt=&quot;table&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The only information this test shows us is the difference in reading a file using fuse-jna and jnr-fuse, but it gives us an understanding of the level of performance difference of JNA and JNR.
If you are interested, you can write a more detailed test for native calls using the &lt;a href=&quot;http://openjdk.java.net/projects/code-tools/jmh/&quot;&gt;JMH&lt;/a&gt; tool.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The performance differences in throughput and latency are about ~10 times. Charles Nutter in his presentation gave us the same numbers.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;_links&quot;&gt;Links&lt;/h3&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/libfuse/libfuse&quot;&gt;FUSE on GitHub&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/jnr&quot;&gt;JNR on GitHub&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;http://www.oracle.com/technetwork/java/jvmls2013nutter-2013526.pdf&quot;&gt;Charles Nutter presentation about JNR&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;http://openjdk.java.net/jeps/191&quot;&gt;JEP 191&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/SerCeMan/jnr-fuse/blob/master/src/main/java/ru/serce/jnrfuse/examples/HelloFuse.java&quot;&gt;Java HelloFuse&lt;/a&gt;/&lt;a href=&quot;https://github.com/libfuse/libfuse/blob/master/example/hello.c&quot;&gt;C HelloFuse&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;The &lt;a href=&quot;https://github.com/SerCeMan/jnr-fuse&quot;&gt;jnr-fuse&lt;/a&gt; project is located on GitHub. I&amp;#8217;ll appreciate stars, pull-requests, and comments.
I&amp;#8217;ll be glad to answer any questions you have about JNR or jnr-fuse.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
<enclosure>

</enclosure>
<pubDate>
Mon, 22 Jun 2015 00:00:00 +0300
</pubDate>
</item>
</channel>
</rss>
